---
number: 3
title: Causal Inference and Model Building
day: 17 februar
type: lecture
layout: remark
---

# {{ page.title }} #
# {{ page.day }} #

???

King, Keohane, and Verba Ch.5 (150-207)
Wooldridge 178-208 (150-180) (model fit), 217-248 (182-211) (dummy variables), 293-324 (241-272) (further issues)
Angrist and Pischke Ch.2-3 (11-24, 27-69, 108-110)
Eveland and Scheufele (2000)
Prior (2005)


---
name: outline1

## Outline

 1. Causal inference

--
name: outline2
 2. Model-building
 
--
name: outline3
 3. Multiple linear regression
 
--
name: outline4
 4. Reporting and interpreting regression results
 

---
template: outline1

---
## Causal Terminology

 - Unit: A physical object at a particular point in time

 - Treatment: An intervention, whose effects we wish to assess relative to some other (non-)intervention

 - Potential outcomes: The outcome for each unit that we would observe if that unit received each treatment

 - Multiple potential outcomes for each unit, but we only observe one of them

 - Causal effect: The comparisons between the unit-level potential outcomes under each intervention

 - Average causal effect

 
---
## Mill's method of difference

> If an instance in which the phenomenon under investigation occurs, and an instance in which it does not occur, have every circumstance save one in common, that one occurring only in the former; the circumstance in which alone the two instances differ, is the effect, or cause, or an necessary part of the cause, of the phenomenon.
 
---
## Causal inference

Causal inference is about estimating *what would have happened* in a counterfactual reality

But we can only observe any given unit in one reality!

This is **the fundamental problem of causal inference**


???

Experiments as a benchmark

- Green et al. (2011) from last week


Try to make our data analysis as experiment-like as possible

  - Sometimes we have quasi-experiments
  
  - But usually we just have to build a good model


---
# "Perfect Doctor" #

True potential outcomes (unobservable in reality)

| Unit | Y(0) | Y(1) |
| ---- | ---- | ---- |
| 1 | 13 | 14 |
| 2 | 6 | 0 |
| 3 | 4 | 1 |
| 4 | 5 | 2 |
| 5 | 6 | 3 |
| 6 | 6 | 1 |
| 7 | 8 | 10 |
| 8 | 8 | 9 |
| *Mean* | *7* | *5* |


???

Pretend we have life expectancy data for 8 patients

We get "God's data", which shows the treatment each patient would have under treatment and control

Clearly, the control is better. On average, patients live longer in the control condition.

---
# "Perfect Doctor" #

How observational data can mislead

| Unit | Y(0) | Y(1) |
| ---- | ---- | ---- |
| 1 | ? | 14 |
| 2 | 6 | ? |
| 3 | 4 | ? |
| 4 | 5 | ? |
| 5 | 6 | ? |
| 6 | 6 | ? |
| 7 | ? | 10 |
| 8 | ? | 9 |
| *Mean* | *5.4* | *11* |


???

Now we only get to see one potential outcome per patient

But our data are not from an experiment

A "perfect doctor" has assigned each patient to the best treatment for them

Now treatment looks much better than control, even though on average it is worse

(This is basic selection bias)


---
## Causal inference

 - How do we draw inferences when we can't observe every potential outcome for each unit?

 - We focus on average causal effects
   - Compare average outcomes among groups of units
   - Try to make comparable those groups by controlling for confounding effects

---

- Causal effects
    - SATE
    - PATE and sampling
  

---
## Causal inference

  - When do our statistical inferences based on observational data have *causal* meaning?

---
## Five criteria

  1. Relationship
  2. Temporal precedence
  3. No confounding
  4. Plausible mechanism
  5. Level of analysis

???

How does regression help us with causal inference?

It only helps with items #1 and #2. Everything else is about research design and philosophical assumptions.


---
## Causation in regression

We need to focus on bias in the estimated relationship (slope coefficient) due to:
 
 - Measurement Error
 
 - Post-treatment bias

 - Confounding

 
---
## Measurement error

Two kinds of measurement error:

 1. Dependent variable
 
 2. Independent variable(s)
 
 




---
## Posttreatment bias

 - We usually want to know the **total effect** of a cause
 
 - If we include a mediator, M, of the X -> Y relationship, the coefficient on X:
  - Only reflects the **direct** effect
  - Excludes the **indirect** effect of X through M

 - So don't control for mediators!
 

???

Is there an example in Eveland and Scheufele? Or in Prior?

Problem is that we can only theorize about possible mediators

---
## Confounding

 - To make a causal claim about a regression coefficient, we need to know that the effect is unconfounded.

 - To do this we can use:
 
   1. Theory
   
   2. Empirical tests of model specification


---
## Common practices

 1. Condition on nothing
   - Estimate a "naive" effect
 
 2. Condition on some variables
   - Theoretically motivated?
   - Data dredging?
 
 3. Condition on observables
   - All observed variables in model
   - All unobserved variables not in model
   

   
---
## Causal models

  - Graphs as expressions of causal theories


---
## Backdoor criterion

How do we know what variables to condition on?

 1. Condition a "fork of mutual dependence" (i.e., confounds)
 
 2. Condition on a complete chain of mediation
 
 3. Do not condition on "colliders" or their descendents
 
 
???

Draw examples on board?

Colliders open back door paths

This is expressed in KKV about relevant versus irrelevant omitted variables


---
background-image: url(http://i.imgur.com/cOX02vk.png)


---
background-image: url(http://i.imgur.com/0AvbiYc.png)


---
background-image: url(http://i.imgur.com/EvJfY5h.png)


????

Instruments (Week 12)


---

  
- Endogeneity
  - Omitted variables


  


---
template: outline4


---
## Empirical model-building
  
 - We can never know the true model
 
 - We can never observe all variables
 
 - We can tell whether and how observed variables should be in the model using residual plots:
   
   1. Plot residuals from a partially specified model against an excluded variable
   
   2. Plot residuals from a fully specified model against an included variable

???

 - Observable versus unobservable variables

 - Observed versus unobserved variables
 
 - We should observe all observable, theoretically important variables

 - **IMPORTANT:** Interactions between variables (see Session 5)
 
---
## Functional form

 - OLS requires the regression model to be "linear in parameters" but the relationship between a given `\(x\)` and `\(y\)` need not be linear
 
 - We can transform variables however we want in order to force a linear relationship
  - We want to produce a linear Conditional Expectation Function
  - To interpret transformations, we need to reverse the transformation to make sense of the coefficient on the original variable scale
 
 - We can have multiple versions of the same variable in a model in order to account for nonlinear relationships
  - Example 1: `\(y \~ \beta_0 + \beta_1 x_1 + \beta_2 x_1^2\)`
  - Example 2: `\(y \~ \beta_0 + \beta_1 x_1 + \beta_2 log(x_1)\)`

 - Identifying appropriate functional form is the same process as identifying appropriate variables to include (theory and residual plots)


---
## RESET test

Can we account for nonlinearities by including power terms?

In Stata:

```
reg growth lcon
ovtest
```

.footnote[Wooldridge pp.296-297]



---
## Influential observations

 - Some observations have high "leverage," having a dramatic influence on the estimated coefficient(s) in a model
 
 - Influential observations are essentially outliers
 
 - They might be multi-dimensional outliers and thus hard to see
 
 - We can measure leverage directly, but often use Cook's Distance
 
???

Cook's Distance incorporates information about residuals in addition to leverage
 
---
## Cook's Distance
 
 - Cook's Distance is calculated by "jacknifing" the regression model
   - Re-running the model *n*-times, leaving out one observation each time
 
 - Run the model with all the data, then compare those coefficients to the jacknifed models
   - Cook's Distance is high when the differences between those coefficients are large
   - `\(n/4\)` is conventional threshold for "high" Cook's Distance
 
 - We can then drop those observations if we're worried about how they influence the model
   - We lose representativeness
   - Possibly gain a better insight into the shape of the relationships in the reduced dataset
  

---
## Influential Observations in Stata

```
use EnglebertPRQ2000.dta

reg growth lcon lconsq
predict newvar, cooksd
summ newvar

* biggest Cook's distance
scalar cookmax = r(max)
tab country if cookmax = newvar

* see Cook's distance by country
tab country, summarize(newvar) nost nofr

* leverage plot
lvr2plot, mlabel(country)
```


---
template: outline4

---
## Interpretation of coefficients

 - In bivariate regression, `\(\beta_1\)` is just the slope (line of best fit)
 
 - In multivariate regression, interpreting coefficients is more complex
   - Imagine a *hyperplane*

 - Accounting for the variation attributable to other variables in the model, what is the effect of `\(x\)` on `\(y\)`
    - Holding all other variables at their means, what is the effect of x on y

???

Instead of thinking of a line of best fit, we have to think about a *hyperplane of best fit* that spans across all of the independent variables
    
---
## Interpretation of coefficients

  - Our interpretations are sample-level interpretations
    - We need to have a representative sample to make population-level inferences
    - But we rarely have truly representative samples
  
  - Uncertainty means coefficients in model are unlikely to be exactly the population-level ("true") effects
    - Better not to think about the point estimates (slopes) but instead the interval

???

Sometimes we have populations

Even random samples are not always representative
 - Bad sampling procedures
 - Nonresponse
 
    
---
## Comparing coefficients
 
 - It's not easy to compare substantive size of coefficients unless regressors have comparable units
 
 - Otherwise it's apples and oranges comparisons
 
 - Sometimes people "standardize" variables (so `\(x\)` becomes `\(x\ast\)`)
   - A standard deviation change in `\(x\)` equals a unit-change in `\(x\ast\)`
   - The coefficient `\(\beta\ast\)` is interpreted as standard deviation changes in `\(y\)` per standard deviation change in `\(x\)`
   - Comparing standardized apples to standardized oranges
      
 - The size of the effect depends on the units of `\(x\)`
    - Think about money: kr versus 1000s of kr; coefficient is larger for 1000s
    
    
---
## Types of variables

 - Interval
 
 - Indicator
 
 - Categorical or ordinal
 
---
## Interval

 - Change in `\(y\)` for a unit-change in `\(x\)`

---
## Indicator

 - Bivariate regression is equivalent to a *t*-test
 
 - Like the example from last week

---
## Categorical

 - Is it ordinal?

 - Treat as interval
   - Be cautious about linearity and the Conditional Expectation Function
   - How categorical variables are coded can affect the estimate since the scale is imposed by the researcher
 
 - Convert to indicators*
   - A series of pairwise comparisons to a baseline condition

.footnote[Wooldridge pp.225-230]
   
---
##

  

---
## Reporting regression results
