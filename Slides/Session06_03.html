---
number: 6
title: Regression with Binary Outcome
day: 17 marts
type: lecture
layout: remark
---

# {{ page.title }} #
# {{ page.day }} #


---
name: outline1

 - Goodness of fit

--
name: outline2

 - Further interpretation
   - Categorical independent variables
   - Interactions
   
--
name: outline3

 - Other categorical outcomes (Session 7_1)


---
template: outline1


---
## Goodness of fit

 - Percent Correctly Classified

 - Likelihood Ratio

 - Pseudo-`\(R^2\)`

---
.left-column[
### Classification

]
.right-column[
## Percent correctly classified
]

---
.left-column[
### Classification

### LR
]
.right-column[
## Deviance (Likelihood ratio)
]
---
.left-column[
### Classification

### LR

### Pseudo-`\(R^2\)`
]
.right-column[
## Pseudo-`\(R^2\)`

 - Different formulae for computing `\( R^2 \)`
   - In OLS, they all produce the same result
   - In GLMs, they produce different results
   
 - Which is correct?
]

???

Goodness-of-fit is not something we think you should worry too much about in these kinds of models

It's an issue, but our focus is on causal inference not on building descriptive or predictive models


---
## Goodness of fit in Stata

```
findit spostado
* install spost9_ado
```

This includes several commands:

 - `fitstat` (Goodness of fit)
 - `prvalue` (Predicted Probabilities)
 - `prchange` (MEs)

---
background-image: url(http://i.imgur.com/XGvfqi4.png)


???


---
background-image: url(http://i.imgur.com/VJZg7i6.png)

???



---
template: outline2


---
## Interactions in OLS

 


???

Review interactions in OLS

Interaction is a difference-in-differencesg


---
## Interactions in logistic regression


???

Interaction is still a difference-in-differences

But how do we measure the difference? In logits (log odds)? Odds? In predicted probabilities?


```
# non-interactive model
set.seed(1)
n <- 200
x <- runif(n,1e-5,1)
y <- rbinom(n,1,x)
g <- glm(y~x, family=binomial(link='logit'))
nx <- seq(0,1,by=.01)
new <- data.frame(x=nx)
f <- predict(g, newdata=new)
p <- predict(g, newdata=new, type='response')
layout(matrix(1:2))
par(mar=c(1,4,1,1), las=1)
plot(nx, f, type='l', lwd=2, bty='l', xlab='', ylab='Logit scale')
par(mar=c(4,4,1,1))
plot(nx, p, type='l', lwd=2, bty='l', xlab='x', ylab='Probability scale')

# interactive model
set.seed(1)
x <- runif(n,1e-5,1)
z <- rbinom(n,1,x)
x2 <- (x + 5) - min((x+5)/5)
y <- numeric(n)
y[z==0] <- rbinom(length(y[z==0]),1,x[z==0])
y[z==1] <- rbinom(length(y[z==1]),1,(x2/max(x2))[z==1])
g <- glm(y~x*z, family=binomial(link='logit'))
nx <- seq(0,1,by=.01)
nz <- 0:1
new <- expand.grid(x=nx,z=nz)
f <- predict(g, newdata=new, se.fit=TRUE)
p <- predict(g, newdata=new, type='response', se.fit=TRUE)
# logit scale
layout(matrix(1:2))
par(mar=c(1,4,1,1), las=1)
plot(new$x[new$z==0], f$fit[new$z==0], type='l', lwd=2, bty='l', xlab='', ylab='Logit scale', ylim=c(-4,6))
lines(new$x[new$z==1], f$fit[new$z==1], lwd=2)
text(.1, 2, "z=1")
text(.1, -1, "z=0")
# predicted probabilities
par(mar=c(4,4,1,1))
plot(new$x[new$z==0], p$fit[new$z==0], type='l', lwd=2, bty='l', xlab='x', ylab='Probability scale', ylim=c(0,1))
lines(new$x[new$z==1], p$fit[new$z==1], lwd=2)
text(.1, .8, "z=1")
text(.1, .2, "z=0")

# marginal effects of z|x
layout(matrix(1:2))
# marginal effects of z (logit scale)
plot(nx, f$fit[new$z==1]-f$fit[new$z==0], type='l', lwd=2, bty='l', xlab='x', ylab='Logit scale', ylim=c(-1,3))
abline(h=0)
b <- cbind.data.frame(x=x,z=z,y=y)
invisible(replicate(100, {
    tmpg <- glm(y~x*z, data=b[sample(1:nrow(b),nrow(b),TRUE),], family=binomial(link='logit'))
    tmpp <- predict(tmpg, newdata=new)
    lines(nx, tmpp[new$z==1]-tmpp[new$z==0], col=gray(.5,.4))
}))
# marginal effects of z (prob scale)
plot(nx, p$fit[new$z==1]-p$fit[new$z==0], type='l', lwd=2, bty='l', xlab='x', ylab='Probability scale', ylim=c(-.2,.5))
abline(h=0)
b <- cbind.data.frame(x=x,z=z,y=y)
invisible(replicate(100, {
    tmpg <- glm(y~x*z, data=b[sample(1:nrow(b),nrow(b),TRUE),], family=binomial(link='logit'))
    tmpp <- predict(tmpg, newdata=new, type='response')
    lines(nx, tmpp[new$z==1]-tmpp[new$z==0], col=gray(.5,.4))
}))

```





---
## Predicted probabilities with interactions


---
## Marginal effects with interactions

