---
number: 12
title: Instrumental Variables
day: 28 april
type: lecture
layout: remark
---

# {{ page.title }} #
# {{ page.day }} #

???

Wooldridge 490-521 (405-436)
Carrubba (2001)
Angrist and Pischke Ch.4 (113-218) and Ch.6 (251-267)
For original article, see: Angrist and Lavy (1999)

IV focuses on estimating a Local Average Treatment Effect (LATE) by finding some real-world randomization to "instrument" for the causal variable

So-called "natural experiments", "regression discontinuity designs", and "interrupted time series" are all basically instrumental variables designs

---
name: outline
## Outline

 1. Review matching
 
 2. Instrumental Variables
 
 3. Regression discontinuity designs

 
---
background-image: url(http://i.imgur.com/Rq3M5Zk.png)

???

I keep my promises - I promised you way back in week 3 when we talked about solving causal graphs that you would learn one more strategy called instrumental variables in week 12. It's week 12 and I'm keeping my promise. I'm sure you've just been dying with anticipation for the last 9 week.

---
## When do we use instrumental variables?

 1. Measurement error
 
 2. Confounding with unobservables
 
???

Because confounding is with unobserved factors, we can't use regression or matching
 

---
background-image: url(http://i.imgur.com/nq4MsDF.png)


???

Causal graph

In regression and matching, we previously focused on closing backdoor paths.

With IV, we focus on finding a variable that precedes our putatively causal variable and that exogenously influences it.


---
## IV in Political Science

 - Widely used in economics
 
 - Increasingly common in political science, but still rare
 
 - Especially common in experimental research

.footnote[Sovey and Green (AJPS, 2010)]


---
## Carrubba (2001)

 - What is his argument?

--

 - Draw a causal graph of his causal argument.
 
--

 - Share with the person sitting next to you.
 
???

Have everyone come up and draw their graph


---
## Instruments

Instruments have to satisfy two properties:

 1. **Exogeneity**
 
 2. **Relevance**

???

What does **exogeneity** mean?

What does **relevance** mean?

 

---
## Instruments

Instruments have to satisfy two properties:

 1. **Exogeneity**
 
   - `\( Z \)` temporally precedes `\( X \)`
   
   - `\( Cov(Z, \epsilon) = 0 \)`
 
 2. **Relevance**

   - `\( Z \)` related to `\( X \)`
   
   - `\( Cov(Z, X) \neq 0 \)`

 
---
background-image: url(http://i.imgur.com/nq4MsDF.png)

---
background-image: url(http://i.imgur.com/ZPImMQw.png)

---
## Instruments

 - **Exogeneity** is not testable

???

Why? We could test it if we had an unbiased estimate of the error term with which to correlate the instrument. If we think there is unobserved confounding, then `\( \beta_1 \)` is biased due to correlation with the error term and so our estimates of the error terms are also biased.

--

 - **Relevance** is testable

???

Why? How?


---
name: questions
class: middle, center

## Questions?

---
## Carrubba (2001)

 - What are Carrubba's instruments?
 
--

 - Are they relevant?
 
???

Yes, he shows the first stage equation

--

 - Are they exogenous?
 
???

We can't test this but we can discuss his defense and draw our own causal graph

The problem is that party positions and public opinion are likely to be dynamic over-time in a game theoretic way (parties influence opinion and opinion influences positions).

Demographics predict opinion at any point in time meaning they can't be instruments because they open back door paths between opinion and lagged party positions.

A better instrument is one that produces a truly exogenous shock. Example: The Fukushima is an exogenous shock to public opinion on nuclear energy. Problem: it may also have directly affected party positions. It's hard to find an instrument for aggregate opinion (but you might be able to find individual-level instruments).

For this question, it might be better to take a panel data or multi-level modelling approach.

 
---
## IV Estimation

 - Several ways to estimate IV model
 
 - We'll focus on Two-Stage Least Squares (2SLS)
 
???

The reason for this is that 2SLS is flexible to multiple instruments

---
## Two-Stage Least Squares

 - `\( Y = \beta_0 + \beta_1 X_{Confounded} + \epsilon \)`
 
 - Estimate of `\( \beta_1 \)` is biased
 
--

 - `\( X_{Confounded} = \rho_0 + \rho_1 Z_{Instrument} + \nu \)`
 
 - `\( Y = \beta_0 + \beta_1^{2SLS} \hat{X} + \epsilon \)`



---
## 2SLS IV Estimation in Stata

```
quietly reg endogenous instrument
predict fitted

* simple estimation
reg outcome fitted

* estimation with additional covariates
reg outcome fitted covariates
```

---
## Standard Errors

 - Standard errors for IV estimates need to incorporate variance in Z
 
 - So, the doing 2SLS manually produces incorrect SEs

 - Luckily, `ivregress` provides functionality directly:

```
ivregress 2sls outcome covariates (confounded = instrument)

* option 'first' gives additional output
ivregress 2sls outcome covariates (confounded = instrument), first

```

---
## Discrete outcomes

Binary outcome:

```
ivprobit outcome covariates (confounded = instrument)
```

Count outcome:

```
ivpoisson gmm outcome covariates (confounded = instrument)
```

.footnote[Note: `gmm` is an alternative estimation method to 2SLS.]

---
## Standard Errors

 - SEs are going to be larger in 2SLS than OLS
 
 - We can still use heteroskedasticity-consistent SEs in second stage
 
???

2SLS is less efficient than OLS which means:

 1. If we can eliminate confounding through straight OLS, we should do it
 
 2. If we have to do 2SLS, we need a larger sample size to obtain the same SEs. Thus it's harder to detect significant effects.

Should we use robust SEs in first stage? No, because we don't care about them...they're irrelevant for generating `\( \hat{X} \)`

---
## An Aside

 - Imagine the confounded variable `\( X \)` is an 0/1 indicator
 
 - Should we use logit/probit to estimate the first stage equation?

???

Differing opinions on this:

 1. Some say no because it builds distributional assumptions into our estimate.
 
 2. But Cameron and Trivedi say you can and show you how to do it in Stata.

---
template: questions
 
 
---
## Assessing IV models

 - We can assess IV fit in the same way as in OLS
 
   - Goodness of fit in first stage (relevance)
   - Goodness of fit in second stage

---
## First stage fit in Stata

```
* full first stage results
ivregress 2sls outcome covariates (confounded = instrument), first

* additional first stage fit statistics
estat firststage
```
   
---
## Assessing IV models

 - We can assess IV fit in the same way as in OLS
 
   - Goodness of fit in first stage (relevance)
   - Goodness of fit in second stage

 - Testing for confounding
 
   - Durbin-Wu-Hausman Test
   - Do residuals from the first stage relate to the outcome?

---
## DWH Test in Stata

```
quietly ivregress 2sls outcome covariates (confounded = instrument)
estat endogenous
```



---
template: questions


---
## Instruments
 
 - Credible/strong instruments
 
 - Weak instruments
 
???

Weak instruments give big SEs


---
## How many instruments?

 1. Exactly identified
 
   - Same number of instruments as confounded variables
 
 2. Overidentified
 
   - More instruments than confounded variables
 
 3. Underidentified
 
   - Fewer instruments than confounded variables

???

Realistically it is pretty rare in the published literature to use more than one instrument. This is generally because it's hard to find one instrument, let alone multiple.


---
## Overidentifying restrictions

 - With multiple instruments we can evaluate a null hypothesis that all instruments are valid
 
 - Rejection of the null implies that at least one of the instruments is invalid
 
 - Failure to reject implies nothing

 - In Stata:

```
quietly ivregress 2sls outcome covariates (confounded = instrument)
estat overid
```

???

This is an omnibus test of all of the instruments to see whether they relate to the confounded `\( X \)` variable

In reality, it's rare that we will even have one instrument let alone enough to test overidentifying restrictions

---
## Instruments versus treatments

 - How does an instrument differ from a treatment variable?
 
 - In other words, if instruments are so good why don't we just look at their direct effects on `\( Y \)`?
 
???

Well, technically an instrument should have no direct effect on Y.

And, most instruments (at least in empirical literature) are things we don't actually care about.

If your instrument is actually a randomized experimental treatment, then we may care about it.

---
## IV Checklist

 1. How/why is the instrument exogenous?
 
 2. How strong is the instrument?
 
 3. Are there other possible instruments?

 
.footnote[Sovey and Green (AJPS, 2010)]
???

Sovey and Green checklist

 1. Instrument must temporally precede the putatively causal variable. There must be no backdoor paths through the instrument to the outcome, nor variables that confound the relationship between the instrument and the putative cause.
 
 2. The instrument must be related to the putative cause.
 
 3. Is this the only available instrument? Are there possibly stronger instruments? What other instruments have been used?




---
template: questions


---
## Activity

 - List of instruments used in published literature
 
 - Assess credibility of the instruments


---
## Forward vs. Backward Causal Inference

 - Forward causal inference
 
 - Backward causal inference
  
???

What are definitions of these ideas?

IV can be used for both, but searching for instruments to solve a particular problem (i.e., backward inference) is really hard. Carrubba tried to find instruments but they weren't great.

Economists tend to use instruments to do forward causal inference. They find an instrument and then leverage it to 

---
template: questions


---
template: outline



---
## Effect Heterogeneity

 - Esimation of any effect is more difficult if we think effects vary across units
 
 - But we can estimate a **Local Average Treatment Effect (LATE)**
 
 - This only applies to "compliers"

???

If the effects of `\( X \)` is constant across individuals (i.e., homogeneous effects), then the IV estimate is an estimate of each individual's causal effect.

But! we rarely believe that all individuals experience the same effect. Instead we think effects vary across individuals. If that's the case, then the IV estimate doesn't represent the effect for everyone. Instead, it is the average effect for a subset of individuals called "compliers".


---
## Four subpopulations

Imagine a binary `\( X \)` and a binary instrument `\( Z \)`

 - Compliers: `\( X = 1 \)` only if `\( Z = 1 \)`
 - Always-takers: `\( X = 1 \)` regardless of `\( Z \)`
 - Never-takers: `\( X = 0 \)` regardless of `\( Z \)`
 - Defiers: `\( X = 1 \)` only if `\( Z = 0 \)`

???

 - Compliers: military service if drafted
 - Always-takers: military service regardless of draft
 - Never-takers: no military service regardless of draft (maybe medically ineligible)
 - Defiers: military service only if not drafted


If we think effects vary across individuals, then IV only estimates the effect for compliers (those who are treated when the instrument is 1 and untreated when the instrument is 0).

Estimation is the same as under constant effects

How do we know which individual units are in which subpopulation? We can't know! Thus the problem with IV estimation under heterogeneous effects is that the external validity of the results is basically undefined.

Because the instrument does not affect `\( X \)` for always-takers and never-takers, we can't use the instrument to say anything about the effect of `\( X \)` on `\( Y \)` for those units.

A big assumption is that there are **no defiers** (an assumption called monotonicity).

---
## Estimating LATE

 - Intention-to-treat effect (`\( ITT \)`)
  
   - `\( E[Y|Z=1] - E[Y|Z=0] \)`

???

This is a weighted average of the four populations:

 1. For Always-takers and Never-takers, the effect is zero because we see the same potential outcomes for them regardless of the value of Z. Z does not affect X for these individuals, so their ITT is 0.
 
 2. We assume no defiers.
 
 3. What is left is the ITT for compliers (the effect of the instrument on Y) times Pr(Complier). But we want to know the effect of X on Y for these individuals. To do that we need to know how many compliers there are in order to divide out to get just the ATE for compliers.

--
   
 - Estimated proportion of compliers (`\( \pi_Compliers \)`)
 
   - `\( Pr(X=1|Z=1) - Pr(X=1|Z=0) \)`

???

Left-hand is Pr(Always-takers) + Pr(Compliers). There are no Never-takers by definition.

Right-hand is Pr(Never-takers) + Pr(Compliers). There are no Always-takers by definition.

We need **monotonicity** (assume no defiers) otherwise the estimated proportion of compliers would be biased because some of the people serving in the control group would be defiers and some of those not serving in the treatment group would be defiers.

Note: We only know the proportion of compliers, not which units actually are compliers due to the fundamental problem of causal inference.

--

 - Result: `\( LATE = \frac{ITT}{\pi_Compliers} \)`
 
???

If there are defiers, the LATE estimate is biased but we don't know by how much or in what direction. We can get monotonicity by design or by assumption.

We can estimate this using two-stage least squares estimator.

---
template: questions

---
## Stop and think

 - Are the SATE (ATE for whole sample) and LATE (ATE for compliers) the same?
 
 - Do we care about the LATE? If so, why? What inferences can we make from it?
 
???

In the draft lottery example, it is telling us about the effect of military service for people who serve because of the draft. It doesn't necessarily tell us about the effect of military service in general. Instead it tell us about the effect of compulsory service.

---
## Aside: Experimentation

 - Earlier, we noted that IV is common in experimental research
 
 - Experiments often involve **noncompliance**
 
   - Some individuals do not take the treatment they are assigned
   
 - IV allows us to estimate the LATE for those who comply with treatment
 
 - Useful for both true experiments and "natural experiments"
 
???

Natural experiment is a real-world assignment process that is random or nearly random


---
## Nearly random instruments

 - Draft (conscription) lotteries

 - Geographical boundaries

 - Weather
 
 - Natural disasters
 
???

 1. Angrist and Krueger
 
 2. Electoral districts in the United States are redrawn every ten years
 
 3. Weather is exogenous - nothing humans do can cause it (as far as we know).
 
 4. Natural disasters: Fukushima, Hurricanes, Floods
 

 
---
## "Sharp" and "Fuzzy" discontinuities

 - If an instrument imperfectly causes `\( X \)`, then it produces a **fuzzy** discontinuity
 
 - If an instrument perfectly causes `\( X \)`, then it produces a **sharp** discontinuity
 
???

Fuzzy discontinuities can be analyzed as IV, like we've discussed up to this point.
 
Sharp discontinuities can be analyzed as randomized experiments. We might even have multiple instruments, then we can match on them or regress on them because we have a complete understanding of the causal process.

---
## Example: Maimonides' Rule
  
 - What is Maimonides' Rule?
 
--

 - Why is it a valid (credible) instrument? (Or why isn't it?)
 
--

 - How does it differ from a randomized experiment?

???

 1. Classes larger than 40 split

 2. Maimonides rule is like an experiment but assignment is only random at the point of the discontinuity. The question is about "bandwidth" - for how many children to the left and to the right of the discontinuity is the discontinuity as-if random? Can we compare a school with 36 children to a school with 44 children? Or can we only compare a school with 39 children to a school with 41?

     What do they find? Class size effect is null

 3. STARS experiment: Tennessee class sizes randomly assigned




---
## Problems with discontinuities

- Compensatory rivalry & equalization

- Campbell's Law:

> The more any quantitative social indicator (or even some qualitative indicator) is used for social decision-making, the more subject it will be to corruption pressures and the more apt it will be to distort and corrupt the social processes it is intended to monitor.

???

 1. Units may behave differently due to their position relative to a threshold, either by trying to be more like the other group or by behaving differently because they know they are being treated. For example: Think about education; teachers in the small class may try harder because they feel like they're expected to do better since they have an easier teaching load. Similarly, those in the large class may try harder to compensate for the fact that they have more students. The discontinuity as instrument thus creates a backdoor path between class size and teacher quality.

 2. Knowing that decisions are based on thresholds, units may attempt to change their position relative to the threshold. Example: If class size determines class size, then parents might try to move their children into the smaller class. The discontinuity thus opens a backdoor path between class size and parental involvement.
 
These are the problems with real-world "quasi-experiments". Discontinuities that appear to be random are often exploited or produce adverse behavior that makes them difficult to exploit for causal inference.

---
template: questions

---
## Preview

 - Tomorrow:
   - IV in Stata
   
 - Next week:
   - Missing Data
   
