---
number: 13
title: Missing Data Imputation
day: 5 maj
type: lecture
layout: remark
---

# {{ page.title }} #
# {{ page.day }} #

???

Gelman and Hill (529-543)
King, Honaker, Joseph, and Scheve (2001)
Gilens (2001)
Simmons and Hopkins (2003)


---
name: outline
## Outline

 1. Instrumental Variables
 
 2. Missing data
 
 3. Single imputation methods
 
 4. Multiple imputation


---
## Missing data

 - What is it?
 
--

 - Why are data missing?
 
--

 - How often do we encounter missing data?

???

Notes:

 - Most data we work with is organized, cleaned, etc.
 - In reality, data are never clean
   - We either have to make them or we get them from someone else
   - Not clean means badly coded and/or full of missing values
   - Coding is something we can handle, missing data is a big problem
 - What do we do when we have missing values?

---
## An Exercise

 - Find your 3rd assignment for this course
 
 - What was the sample size for your model?

 
---
## Wooldridge

 - Wooldridge only mentions missing data once:
 
> If the data are missing at random, then the size of the random sample available from the population is simply reduced. Although this makes the estimators less precise, it does not introduce any bias [...] There are ways to use the information on observations where only some variables are missing, but this is not often done in practice. The improvement in the estimators is usually slight, while the methods are somewhat complicated. In most cases, we just ignore the observations that have missing information.

.footnote[Wooldridge p.314]


---
## Mising Data In Practice

 - Ideally we don't have any missing data

 - Since this is never the case we have to respond to it

---
## Effects of Missing Data

 1. Statistical efficiency
 
 2. Comparability of analyses
 
 3. Representativeness
 
 4. Scale construction
 
 5. Causal inference

???

Statistical efficiency (loss of information; effect on SEs)

Representativeness

Comparability of analyses

Scale construction (measurement error due to missingness)

Problem from a causal perspective: if missingness perfectly determined by a third variable, then we're estimating an implicit interaction and only seeing the effect for those with available data.



---
## Scaling

  - We haven't talked a lot about scaling in this class
  
  - How do we build scales with missing values?


---
## An Example

 - We often use simple additive scales
 
???

Examples: 

 - Number of acts of political participation
 - Number of correct political knowledge questions
 - Number of features of a democracy

--

| Case | Item 1 | Item 2 | Item 3 | Sum |
| --- | --- | --- | --- | --- |
| A | 1 | 2 | 1 | ? |
| B | 1 | . | 3 | ? |
| C | . | 1 | 1 | ? |
| D | 2 | 1 | 2 | ? |
| E | 1 | . | . | ? |
| F | . | . | . | ? |

???

What are the scores for each case in this dataset?
  
---
## Two Default Approaches

 1. Complete Case Analysis
 
   - i.e., listwise deletion
   
 2. Available Case Analysis
 
   - This is our default

---
## Available Case Analysis
  
 - Software default

 - Remove any observations with missing values for a given analysis
 
 - Benefits
    - Easy
    - Uses as much data as possible for any given analysis

 - Consequences
    - Loss of information
    - Analyses are not comparable to one another
    - Loss of sample representativeness?

???

Worst solution because it is the default. It's done unconsciously.

---
## Complete Case Analysis

 - Listwase or case deletion
 
 - Remove any observations with missing values before all analyses
 
 - Benefits
    - Easy
    - All analyses are comparable to one another

 - Consequences
    - Loss of information (more than available case)
    - Loss of sample representativeness?

???

Challenging because you need to identify all of your variables in advance of running any analyses, so you can drop those with missing values



---
## What can we do about missing data?

 - Use default strategies
 
 - Impute missing values once
 
 - Run analyses multiple times with different imputations

---
## Missing Data Assumptions

 1. **Missing Completely At Random** (MCAR)
 
 2. **Missing At Random** (MAR; Ignorable)
 
 3. **Nonignorable** (NI)

--

 4. **Censoring**
 
???

What do these assumptions mean?

Unfortunately, we can't really test them. We can see whether missingness is independent of observed variables, but not unobserved variables.

We don't talk about censoring in this course, but it is when missingness on a variable depends on the variable itself. There are various strategies for addressing this like Heckman selection models, Tobit models, etc. All of these are forms of Generalized Linear Models.

---
## Examples?

 1. **Missing Completely At Random** (MCAR)
 
???

Randomly didn't ask some people some questions on a survey.

You as the researcher were carrying the data on paper in a randomly shuffled order and some of the pages blew away in the wind.

--

 2. **Missing At Random** (MAR; Ignorable)
 
???

Responses to a survey question are determined by demographic characteristics. E.g., whether or not someone reports their ideology is a function of their age, sex, and education. We can model missingness in the ideology variable based upon those demographics.

--

 3. **Nonignorable** (NI)

???

Whether or not someone reports their ideology is a function of their ideology, or worse an unmeasured third variable (e.g., their personality)


---
## MCAR

 1. Statistical efficiency
 
 2. Comparability of analyses
 
 3. Representativeness
 
 4. Scale construction
 
 5. Causal inference

???

Which of these is a problem?

---
## MAR/Ignorable

 1. Statistical efficiency
 
 2. Comparability of analyses
 
 3. Representativeness
 
 4. Scale construction
 
 5. Causal inference

???

Which of these is a problem?

---
## NI

 1. Statistical efficiency
 
 2. Comparability of analyses
 
 3. Representativeness
 
 4. Scale construction
 
 5. Causal inference

???

Which of these is a problem?


---
name: questions
class: middle, center

## Questions?


---
template: outline

---
## Single imputation

 - Impute missing values once
 
 - Benefits
   - Increases statistical efficiency
   - Comparable analyses
   - Easy (depends on technique)
   - Preserve representativeness?
 
 - Consequences
   - Bias (depends on technique)
   - Analyses do not reflect uncertainty due to missingness

   
???

In practice this is not all that common.

Consequence: replacement of missing values is potentially arbitrary; if missingness is ignorable (MAR), we need to model the missingness

- Modifies the features of univariate and multivariate distributions
      - Might change central tendency (mean, median), variance, etc.
    - How to calculate standard errors?

---
## Single Imputation Methods

 - Single value (e.g. zero, mean)

 - Random value
 
 - Inferred value

 - Hot deck
 
 - Regression
    
???

Notes:

 1. Single value. What effect does this have on mean, variance, correlations? None, smaller, smaller
 
 2. Random value.
   - What distribution to draw from? Allowed values, allowed value weighted by their prevalence in the data? Continuous distribution?
   - What effect does this have on mean, variance, correlations? None, none, smaller
 
 3. Inferred value.
   - Use other data to infer a value. If income is missing, but R said they are unemployed, income is presumably zero.
   - What effect does this have on mean, variance, correlations? some, some, some
 
 4. Hot deck.
   - Use information in the dataset to infer values.
   - Based on cross-tabulation.
   - All cases that have the same set of observed values will have the same imputed value (no account for random variation)
   - What effect does this have on mean, variance, correlations? some, some, some
 
 5. Regression.
   - Use information in the dataset to infer values.
   - Uses standard regression techniques to make out-of-sample predictions. Fitted value from regression is used as imputed value.
   - All cases that have the same set of observed values will have the same imputed value (no account for random variation).
   - What effect does this have on mean, variance, correlations? some, some, some
   - Note: We can use regression and then add random error onto the imputed values to inflate our variance estimates.

---
## Regression Imputation

 - Fill in missing values using fitted values from a regression model
 
 - We can use any variable in this model
   - There is no need to respect causal ordering
 
 - Should we impute missing outcome values?
 
???

There seems to be a view that we should not impute missing outcome data. This is a point of contention and there are advocates of imputing all variables.

The challenge is that when you impute missing data for an outcome as a function of covariates and then use those covariates to model the outcome, it is no surprise that the outcome is a function of those covariates.


---
template: questions

---
template: outline


---
## Multiple Imputation (MI)

 1. Engage a single imputation method
 
 2. Repeat this method multiple times to create multiple imputed datasets
 
 3. Run analysis on each imputed dataset
 
 4. Combine estimates and calculate combined variances

???

How many imputed datasets do we need?

The answer is surprisingly small. Generally 5. Unless there is a dramatic amount of missingness, this is only 5% less efficient than imputing an infinite number of times.

There are different algorithms for doing this:
 - King et al. have one
 - Gelman and Hill have another one
 - There are others
 
The basic idea in most of these is to model all of the variables with missingness as a multivariate function of all other variables. The computation details aren't really important.

---
## Multiple Imputation (MI)

 - Benefits
   - Increases statistical efficiency
   - Account for uncertainty due to missingness
   - Comparable analyses
   - Better than single imputation if MAR
   
 - Consequences
   - Somewhat computationally expensive
   - Challenging with large datasets
   - Software may not, by default, handle all statistical tests in an MI framework

---
## Multiple Imputation (MI)

 - Easy if missingness only on one variable
 
 - More complicated if missingness on multiple variables
 
 - Still not very commonly used in political science
 
 - Doesn't solve NI missingness


 
---
## Aggregating MI Results

 1. Run analysis on each imputed dataset
 
 2. Each analysis produces a test statistic `\( \hat{\beta}_m \)`
 
 3. Overall test statistic is `\( \Sigma_1^M \hat{\beta}_m \)`
 
 4. Calculating variance is a sum of two things:
 
   - *within*-imputation variance
   - *between*-imputation variance
   
---
## Variance of MI Estimates

 - Within-imputation variance:
 
    `\( Within = \frac{1}{m}\Sigma_1^M \hat{V}_m \)`

 - Between-imputation variance:
 
    `\( Between = \frac{1}{m-1} \Sigma_1^M (\hat{\beta}_m - \hat{\beta})^2 \)`
     
 - Total variance is:

    `\( V_{\beta} = Within + (1 + \frac{1}{m}) Between \)`

---
## An Example

 - What is the effect of university education on an individuals' political tolerance?
   - University education is a binary indicator
   - Tolerance is on an 11-point scale
 
 - Missingness in various covariates
 
 - Multiply impute missing values
 
 - On each imputed dataset, we regress Tolerance on Education + Controls
 
 - Our test statistic is `\( \beta_Educ \)`

---
## An Example

 - Here are some MI results:

| Dataset | `\( \beta_{Educ} \)` | `\( SE_\beta \)` |
| --- | --- | --- |
| 1 | 4.32 | 0.95 |
| 2 | 4.15 | 1.16 |
| 3 | 4.86 | 0.83 |
| 4 | 3.98 | 1.04 |
| 5 | 4.50 | 0.91 |

 - What is the overall `\( \beta_{Educ} \)` ?
 
 - What is the overall `\( SE_{\beta} \)` ?

???

| Dataset | `\( \beta_{Educ} \)` | `\( SE_\beta \)` | `\( Var(\beta_Educ) \)` |
| --- | --- | --- | --- |
| 1 | 4.32 | 0.95 | 0.9025 |
| 2 | 4.15 | 1.16 | 1.3456 |
| 3 | 4.86 | 0.83 | 0.6889 |
| 4 | 3.98 | 1.04 | 1.0816 |
| 5 | 4.50 | 0.91 | 0.8281 |

`\( \beta_{Overall} = 4.362 \)`
 
`\( Var_{Within} = \frac{1}{5} (0.9025 + 1.3456 + 0.6889 + 1.0816 + 0.8281) = \frac{4.8467}{5} = 0.96934\)`

`\( Var_{Between} = \frac{1}{m-1}(-0.042^2 + 0.212^2 + 0.498^2 + -0.382^2 + 0.138^2) = \frac{0.45968}{4} = 0.11492 \)`

`\( Var_\beta = W + (1 + \frac{1}{m}) B = 0.96934 + (1 + .2) (0.11492) = 1.107244 \)`

`\( SE_\beta = \sqrt{1.107244} = 1.052257 \)`

( The raw mean of SEs is 0.978. The sqrt of the mean of the raw variances is 0.96934. )

---
template: questions

---
## Summary

 - Missing data is a common problem
 
 - Multiple strategies for coping with it
 
 - Some better than others
 
 - For exam and real life, be prepared to justify your strategy for addressing missing data
 
 
